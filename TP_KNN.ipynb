{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOumrYmz3rtWphSf0G4SG+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/man237/man237/blob/main/TP_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FENTCHOU DONGWA GILLES AUBIN  18T2850\n",
        "\n",
        "KENNE TAKOUDJOU FRANCK MANUEL 19M2074\n",
        "\n",
        "MOUAFO PAULE-SOPHIE 19M2232\n",
        "\n",
        "MAGNE SIGNE MUREILLE SHARANE 19M2166"
      ],
      "metadata": {
        "id": "RY9EbAlmmJWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bibliothèques utilisées**"
      ],
      "metadata": {
        "id": "abj1wC-WmZeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMNs_o6qkpuA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os : pour ouvrir et lire des fichiers.\n",
        "\n",
        "string : pour la liste de ponctuation\n",
        "\n",
        "Stopwords : contient la liste des mots vides.\n",
        "\n",
        "Train_test_split : pour diviser les données en données \n",
        "\n",
        "d'apprentissage et de test.\n",
        "\n",
        "Accuracy_score :pour calculer la précision des algorithmes.\n",
        "\n",
        "Numpy : pour permettre une manipulation avancée des tableaux.\n"
      ],
      "metadata": {
        "id": "t7JCbRrYmG0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des données\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "soeiHf_LnBfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    print(\"Loading data...\")\n",
        "    \n",
        "    ham_files_location = os.listdir(\"dataset/ham\")\n",
        "    spam_files_location = os.listdir(\"dataset/spam\")\n",
        "    data = []"
      ],
      "metadata": {
        "id": "WrTtcYCYkvlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                             os.listdir() \n",
        "renvoie une liste de tous les noms de fichiers à l'intérieur d'un dossier. Ceci est utilisé pour récupérer tous les noms de fichiers des fichiers texte dans chacun des dossiers ham et spam et les stocker respectivement dans ham_files_location et spam_files_location. data est une liste pour stocker chaque texte d'e-mail et son étiquette correspondante."
      ],
      "metadata": {
        "id": "UvGKxCqBl_jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ham email\n",
        "for file_path in ham_files_location:\n",
        "  f = open(\"dataset/ham/\" + file_path, \"r\")\n",
        "  text = str(f.read())\n",
        "  data.append([text, \"ham\"])\n",
        "    \n",
        "# Load spam email\n",
        "for file_path in spam_files_location:\n",
        "  f = open(\"dataset/spam/\" + file_path, \"r\")\n",
        "  text = str(f.read())\n",
        "  data.append([text, \"spam\"])"
      ],
      "metadata": {
        "id": "7rSeQvgam87-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous parcourons la liste des noms de fichiers de texte ham, utilisons open () pour ouvrir un fichier, puis utilisons str (f.read ()) pour lire le texte de l'e-mail sous forme de chaîne et le stocker dans un texte variable. Une liste composée de texte et l'étiquette correspondante \"ham\" sont ajoutées aux données de la liste."
      ],
      "metadata": {
        "id": "fcugdL2exvfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "    \n",
        "print(\"flag 1: loaded data\")\n",
        "return data"
      ],
      "metadata": {
        "id": "6S0-eDBAxxZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Les données de la liste sont transformées en un tableau numpy, pour permettre une meilleure manipulation du tableau ultérieurement. les données sont ensuite renvoyées.\n",
        "\n"
      ],
      "metadata": {
        "id": "AAYVrgBkzFBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prétraitement des données"
      ],
      "metadata": {
        "id": "9yyZ-wS5zOsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data: noise removal\n",
        "def preprocess_data(data):\n",
        "    print(\"Preprocessing data...\")\n",
        "    \n",
        "    punc = string.punctuation           # Punctuation list\n",
        "    sw = stopwords.words('english')     # Stopwords list"
      ],
      "metadata": {
        "id": "ASA6erIZzaCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "punc contient une liste de ponctuation et de symboles\n",
        "sw contient une liste de mots vides de la bibliothèque nltk.corpus\n"
      ],
      "metadata": {
        "id": "pUK88AAm0Brh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for record in data:\n",
        "# Remove common punctuation and symbols\n",
        "  for item in punc:\n",
        "    record[0] = record[0].replace(item, \"\")\n"
      ],
      "metadata": {
        "id": "TKAAWhYf0FvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour chaque enregistrement dans data, pour chaque élément (symbole ou ponctuation) dans punct, remplacez l'élément par une chaîne vide, pour supprimer l'élément de record[0] (chaîne de texte d'e-mail)."
      ],
      "metadata": {
        "id": "_CUA1JfQ1Mux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Lowercase all letters and remove stopwords \n",
        "splittedWords = record[0].split()\n",
        "newText = \"\"\n",
        "for word in splittedWords:\n",
        "  if word not in sw:\n",
        "    word = word.lower()\n",
        "    newText = newText + \" \" + word  \n",
        "  record[0] = newText\n",
        "        \n",
        "  print(\"flag 2: preprocessed data\")\n",
        "  return data"
      ],
      "metadata": {
        "id": "4ktm0oD81U8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez la méthode split () sur l'enregistrement de texte de l'e-mail [0] pour renvoyer une liste de tous les mots de l'e-mail. Parcourez cette liste de mots, et si le mot n'est pas dans la liste des mots vides, mettez-le en minuscules et ajoutez le mot à newText. newText contiendra l'e-mail mais vide de mots vides. newText est réattribué à record[0]. Une fois que chaque enregistrement [0] a été prétraité, les données nettoyées sont renvoyées.\n",
        "\n",
        "Fractionnement des données en ensembles d'apprentissage et de test\n",
        "L'ensemble de données est divisé en un ensemble d'apprentissage (73 %) et un ensemble de test (27 %).\n",
        "\n"
      ],
      "metadata": {
        "id": "mVQuF9nZ28y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting original dataset into training dataset and test dataset\n",
        "def split_data(data):\n",
        "    print(\"Splitting data...\")\n",
        "    \n",
        "    features = data[:, 0]   # array containing all email text bodies\n",
        "    labels = data[:, 1]     # array containing corresponding labels\n",
        "    print(labels)\n",
        "    training_data, test_data, training_labels, test_labels =\\\n",
        "        train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
        "    \n",
        "    print(\"flag 3: splitted data\")\n",
        "    return training_data, test_data, training_labels, test_labels"
      ],
      "metadata": {
        "id": "RY_WG6Pj3kuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# L'algorithme KNN"
      ],
      "metadata": {
        "id": "CA_6Ccxa5e94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " la fonction get_count() "
      ],
      "metadata": {
        "id": "vHzBM8Sm5nG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(text):\n",
        "    wordCounts = dict()\n",
        "    for word in text.split():\n",
        "        if word in wordCounts:\n",
        "            wordCounts[word] += 1\n",
        "        else:\n",
        "            wordCounts[word] = 1\n",
        "    \n",
        "    return wordCounts"
      ],
      "metadata": {
        "id": "uN95QdSq5jOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction prend un seul texte d'e-mail et le divise à l'aide de split(). La fréquence d'occurrence de chaque mot dans l'e-mail est comptée et enregistrée dans wordCounts, qui est de type dictionnaire. Le dictionnaire wordCounts est ensuite renvoyé."
      ],
      "metadata": {
        "id": "BFAYznDx6HrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " la fonction euclidean_difference()"
      ],
      "metadata": {
        "id": "2FHnbuTQ6W_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
        "    total = 0"
      ],
      "metadata": {
        "id": "Px9dpmuv6cbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction prend en compte un dictionnaire de nombre de mots d'un e-mail de test test_WordCounts et un autre dictionnaire d'un e-mail de formation, training_wordCounts. total stocke la somme de la différence au carré de la fréquence d'un mot dans l'e-mail de test et d'entraînement."
      ],
      "metadata": {
        "id": "VVDOgrFZ6jZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in test_WordCounts:\n",
        "        if word in test_WordCounts and word in training_WordCounts:\n",
        "            total += (test_WordCounts[word] - training_WordCounts[word])**2"
      ],
      "metadata": {
        "id": "3VSwmgbB6uUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout d'abord, nous parcourons les mots du dictionnaire d'e-mails de test. Pour chaque mot, il y a trois cas. Le premier cas est qu'il existe à la fois dans l'e-mail de test et dans l'e-mail de formation. Dans ce cas, le total est incrémenté de la différence au carré de la fréquence du mot dans l'e-mail de test et l'e-mail de formation."
      ],
      "metadata": {
        "id": "5eVfv2jn695W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del training_WordCounts[word]"
      ],
      "metadata": {
        "id": "E9fBELKL7ELc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ensuite, le mot commun est supprimé du dictionnaire des e-mails de formation, pour accélérer la prochaine boucle for\n",
        "else:\n"
      ],
      "metadata": {
        "id": "07YaHXr17M2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "else:\n",
        "  total += test_WordCounts[word]**2\n"
      ],
      "metadata": {
        "id": "06HBdjL-7Rrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le deuxième cas est que le mot est uniquement dans l'e-mail de test. Dans ce cas, il n'est pas nécessaire de trouver la différence (puisque sa fréquence est de 0 dans l'e-mail de formation), nous ajoutons donc simplement la fréquence au carré du mot au total."
      ],
      "metadata": {
        "id": "o3JXWJON7VUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in training_WordCounts:\n",
        "  total += training_WordCounts[word]**2"
      ],
      "metadata": {
        "id": "LZqGb4Kv7pQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dernier cas est que le mot est uniquement dans l'e-mail de formation. Étant donné que nous avons supprimé tous les mots courants dans la boucle for précédente, nous parcourons simplement le dictionnaire des e-mails de formation et ajoutons la fréquence au carré de chaque mot au total."
      ],
      "metadata": {
        "id": "1Xvt9RM07xjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "return total**0.5"
      ],
      "metadata": {
        "id": "lPmDFDtT74n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, la racine carrée du total (la racine carrée de la somme de la différence au carré des fréquences de chaque mot) est renvoyée sous la forme d'un double. C'est la fin de la fonction de calcul de la distance euclidienne."
      ],
      "metadata": {
        "id": "oblXMFng77gW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " la fonction get_class() "
      ],
      "metadata": {
        "id": "HnOoty8p8LBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(selected_Kvalues):\n",
        "    spam_count = 0\n",
        "    ham_count = 0\n"
      ],
      "metadata": {
        "id": "w10P5dWK8JiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction prend en compte la liste des K plus proches voisins sélectionnés pour déterminer la classe de l'email de test en cours. spam_count et ham_count stockent la fréquence d'occurrence de chaque étiquette \"spam\" et étiquette \"ham\" respectivement dans les K voisins les plus proches sélectionnés."
      ],
      "metadata": {
        "id": "8Bt54Y958Y--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    for value in selected_Kvalues:\n",
        "        if value[0] == \"spam\":\n",
        "            spam_count += 1\n",
        "        else:\n",
        "            ham_count += 1"
      ],
      "metadata": {
        "id": "9vIyF_b68jn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En utilisant une boucle for, pour chaque valeur parmi les K valeurs sélectionnées, si la valeur de l'étiquette [0] est égale à \"spam\", alors spam_count est incrémenté de 1. Sinon, ham_count est incrémenté de 1."
      ],
      "metadata": {
        "id": "8Rgx5r6I8zng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    if spam_count > ham_count:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"ham\"\n"
      ],
      "metadata": {
        "id": "WMwz7-Qm89LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après la boucle for, si spam_count est supérieur à ham_count, cela signifie que l'e-mail de test actuel a plus tendance à être du spam, donc une chaîne \"spam\" est renvoyée comme étiquette prédite. Sinon, la chaîne \"ham\" est renvoyée comme étiquette prédite.\n",
        "\n"
      ],
      "metadata": {
        "id": "lavbHxKi9Kd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "knn_classifier() function"
      ],
      "metadata": {
        "id": "d-F9i5wH9RAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
        "    print(\"Running KNN Classifier...\")\n",
        "    \n",
        "    result = []\n",
        "    counter = 1"
      ],
      "metadata": {
        "id": "2QNeEugM9WgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est la fonction de classificateur KNN. Il prend en compte l'e-mail de formation, les étiquettes de formation, les données de test, la valeur K et le nombre d'e-mails de test à tester sur les 27 % d'e-mails de test d'origine. result est la liste qui contiendrait les étiquettes prédites. compteur sera simplement utilisé à des fins d'affichage pour indiquer la progression lorsque le programme est exécuté."
      ],
      "metadata": {
        "id": "kV3qlw_y9j5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # word counts for training email\n",
        "    training_WordCounts = [] \n",
        "    for training_text in training_data:\n",
        "            training_WordCounts.append(get_count(training_text))"
      ],
      "metadata": {
        "id": "cUnqmGXr9qPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étant donné que l'ensemble de formation est constant, nous pouvons compter une fois pour toutes la fréquence des mots dans chaque e-mail de formation. Ainsi, pour chaque texte d'e-mail dans les données d'apprentissage, son dictionnaire de fréquence de mots est obtenu à l'aide de get_count(). Le dictionnaire est ensuite ajouté à la liste training_WordCounts pour être stocké."
      ],
      "metadata": {
        "id": "kYjxxBXP90Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    for test_text in test_data:\n",
        "        similarity = [] # List of euclidean distances\n",
        "        test_WordCounts = get_count(test_text)  # word counts for test email"
      ],
      "metadata": {
        "id": "Tujj5ajs95q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Désormais, pour chaque e-mail de test dans les données de test, les opérations suivantes sont effectuées. Une similarité de liste vide est déclarée. Il stockera les distances euclidiennes entre l'e-mail de test actuel et chaque e-mail d'entraînement. Ensuite, le dictionnaire de fréquence des mots de l'e-mail de test est obtenu à l'aide de get_count()."
      ],
      "metadata": {
        "id": "-6nT0ROS-E1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting euclidean difference \n",
        "for index in range(len(training_data)):\n",
        "euclidean_diff =\\\n",
        "euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
        "similarity.append([training_labels[index], euclidean_diff])\n"
      ],
      "metadata": {
        "id": "axuk_fUkelUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puisque nous avons déjà les dictionnaires de fréquence de mots de tous les e-mails de formation et l'e-mail de test actuel. Nous pouvons continuer à calculer la distance euclidienne entre l'e-mail de test actuel et chaque e-mail d'entraînement à l'aide d'une boucle for qui itère x fois, où x est égal à la taille de l'ensemble de données d'entraînement. Après chaque itération, la distance euclidienne calculée est ajoutée à la liste de similarité, ainsi que l'étiquette correspondante de l'e-mail d'entraînement.\n",
        "\n"
      ],
      "metadata": {
        "id": "gorTdcDneq0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort list in ascending order based on euclidean difference\n",
        "similarity = sorted(similarity, key = lambda i:i[1])\n"
      ],
      "metadata": {
        "id": "QW3kkF5Ke7YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après que toutes les distances euclidiennes ont été stockées. Nous trions la liste de similarité par ordre croissant en fonction de la deuxième colonne, c'est-à-dire en fonction de la distance euclidienne (du plus proche au plus éloigné)."
      ],
      "metadata": {
        "id": "9d2Zi1XsfFGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select K nearest neighbours\n",
        "selected_Kvalues = [] \n",
        "for i in range(K):\n",
        "selected_Kvalues.append(similarity[i])\n"
      ],
      "metadata": {
        "id": "Y_l7GgjqfM1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, puisque la liste de similarité est déjà triée, nous pouvons facilement ajouter les K voisins les plus proches à la liste selected_Kvalues en utilisant une simple boucle for."
      ],
      "metadata": {
        "id": "zwu-_CT4fR8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the class of email\n",
        "result.append(get_class(selected_Kvalues))\n"
      ],
      "metadata": {
        "id": "FpLe9TtTfZte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, et avant de passer au prochain e-mail de test. Nous déterminons la classe de l'e-mail de test actuel à l'aide de get_class(). Maintenant, nous avons atteint la fin d'une itération, et la prochaine itération peut commencer à classer le prochain e-mail de test."
      ],
      "metadata": {
        "id": "ZVeo35d0fgnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "return result"
      ],
      "metadata": {
        "id": "bGjhvzJoflob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main() function"
      ],
      "metadata": {
        "id": "oSY7dNV6fvk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(K):\n",
        "    data = load_data()\n",
        "    data = preprocess_data(data)\n",
        "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Npn3amwDfyek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est la fonction principale où le programme commence à s'exécuter. C'est là que tout est mis en place. La fonction principale prend la valeur K. Tout d'abord, tous les e-mails sont chargés à l'aide de load_data(), puis stockés dans data. Les e-mails sont ensuite prétraités à l'aide de preprocess_data() et stockés à nouveau dans data. les données sont ensuite divisées en training_data, test_data, training_labels et test_labels à l'aide de split_data()."
      ],
      "metadata": {
        "id": "YTt1UQ5Df2uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsize = len(test_data)CXD"
      ],
      "metadata": {
        "id": "k4amXYVYgBfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tsize spécifie le nombre d'e-mails de test (sur les 27 % de données de test d'origine) pour prédire leurs étiquettes. Actuellement, tsize est défini pour être égal à l'ensemble des e-mails de test."
      ],
      "metadata": {
        "id": "U5Tef1YHgDGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize) \n",
        "accuracy = accuracy_score(test_labels[:tsize], result)\n"
      ],
      "metadata": {
        "id": "-GMKjDHKhLfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, la fonction knn_classifier() est appelée pour prédire les étiquettes des e-mails de test. La liste renvoyée des étiquettes prédites est stockée dans le résultat. Après cela, la précision est calculée à l'aide de la méthode precision_score() de la bibliothèque sklearn. Cette méthode compare la liste d'étiquettes réelle test_labels avec le résultat de la liste d'étiquettes prédite."
      ],
      "metadata": {
        "id": "X_zuGYR3hRez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training data size\\t: \" + str(len(training_data)))\n",
        "print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
        "print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
        "print(\"Samples tested\\t\\t: \" + str(tsize))\n",
        "print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
        "\n",
        "print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
        "print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) *\n",
        "\n"
      ],
      "metadata": {
        "id": "J0xq5zYbhYml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ces lignes affichent les détails de l'exécution tels que la taille des données de formation, la taille des données de test, la valeur K, le nombre d'échantillons testés, le pourcentage de précision, le nombre d'e-mails correctement identifiés et le nombre d'e-mails faussement identifiés."
      ],
      "metadata": {
        "id": "a7XMQiC-hh0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(11)\n",
        "\n"
      ],
      "metadata": {
        "id": "t0LFHEcEhoc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, c'est la ligne qui lance le programme en appelant la fonction main, et lui donne la valeur K (qui est 11 dans ce cas)."
      ],
      "metadata": {
        "id": "g8knX1ejhuuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Résultat et conclusion"
      ],
      "metadata": {
        "id": "kQXONPO8h1o9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ceci est la sortie finale de tout le code qui a été expliqué ci-dessus. On peut voir que l'utilisation de l'algorithme KNN pour classer les e-mails en spam et jambon, avec une valeur K de 11 et une taille de données de test de 1582, donne un taux de précision de 76,7 %. Même s'il n'est pas le meilleur, il est satisfaisant. Un bémol à noter est qu'il faut beaucoup de temps pour classer les 1582 emails. Cela est principalement dû à la complexité temporelle élevée, qui est le résultat de trois boucles for imbriquées lors du calcul de la différence euclidienne entre les e-mails de test et les e-mails de formation."
      ],
      "metadata": {
        "id": "pPCApCpriSjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s1cnfYkxiXza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}